{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import unicodedata\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Bidirectional, SimpleRNN, TimeDistributed, LSTM, GRU, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = treebank.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "labels = []\n",
    "vocab = set([])\n",
    "pos = set([])\n",
    "maxLength = 0\n",
    "argmaxLength = 0\n",
    "\n",
    "for sentence in sentences:\n",
    "    \n",
    "    if maxLength<len(sentence):\n",
    "        maxLength = len(sentence)\n",
    "        argmaxLength = sentence\n",
    "    example = []\n",
    "    label = []\n",
    "    for unit in sentence:\n",
    "        word = unit[0].lower()\n",
    "        example.append(word)\n",
    "        label.append(unit[1])\n",
    "        vocab.add(word)\n",
    "        pos.add(unit[1])\n",
    "    examples.append(example)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "input_tokenizer.fit_on_texts(examples)\n",
    "input_tensor = input_tokenizer.texts_to_sequences(examples)\n",
    "input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "pos_tokenizer.fit_on_texts(labels)\n",
    "pos_tensor = pos_tokenizer.texts_to_sequences(labels)\n",
    "pos_tensor = tf.keras.preprocessing.sequence.pad_sequences(pos_tensor,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train,input_val,output_train, output_val = train_test_split(input_tensor,pos_tensor,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_train)\n",
    "BATCH_SIZE = 32\n",
    "steps_per_epoch = len(input_train)//BATCH_SIZE\n",
    "embedding_dim = 20\n",
    "vocab_inp_size = len(vocab)+1\n",
    "vocab_tar_size = len(pos)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((input_train, output_train)).shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((input_val, output_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([Embedding(vocab_inp_size, embedding_dim,input_length = input_train.shape[1], name=\"embedding\"),\n",
    "                    SimpleRNN(64,return_sequences=True),\n",
    "                    TimeDistributed(Dense(vocab_tar_size, activation='softmax'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 271, 20)           227760    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 271, 64)           5440      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 271, 13)           845       \n",
      "=================================================================\n",
      "Total params: 234,045\n",
      "Trainable params: 234,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - ETA: 0s - loss: 1.3650 - accuracy: 0.8327WARNING:tensorflow:Model was constructed with shape (None, 271) for input Tensor(\"embedding_input:0\", shape=(None, 271), dtype=float32), but it was called on an input with incompatible shape (271, 1).\n",
      "97/97 [==============================] - 7s 76ms/step - loss: 1.3650 - accuracy: 0.8327 - val_loss: 2.5154 - val_accuracy: 0.9046\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 7s 72ms/step - loss: 0.5623 - accuracy: 0.8937 - val_loss: 2.4983 - val_accuracy: 0.9055\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 7s 74ms/step - loss: 0.4708 - accuracy: 0.8981 - val_loss: 2.4891 - val_accuracy: 0.9064\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 7s 73ms/step - loss: 0.4352 - accuracy: 0.8984 - val_loss: 2.4777 - val_accuracy: 0.9091\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 7s 73ms/step - loss: 0.3275 - accuracy: 0.9099 - val_loss: 2.4650 - val_accuracy: 0.9114\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 7s 73ms/step - loss: 0.2986 - accuracy: 0.9104 - val_loss: 2.4534 - val_accuracy: 0.9138\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 7s 75ms/step - loss: 0.2838 - accuracy: 0.9118 - val_loss: 2.4422 - val_accuracy: 0.9154\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 7s 73ms/step - loss: 0.2779 - accuracy: 0.9140 - val_loss: 2.4300 - val_accuracy: 0.9181\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 7s 76ms/step - loss: 0.2909 - accuracy: 0.9122 - val_loss: 2.4174 - val_accuracy: 0.9213\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 7s 76ms/step - loss: 0.2753 - accuracy: 0.9177 - val_loss: 2.3999 - val_accuracy: 0.9228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x146669810>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset,epochs=10,validation_data=val_dataset,validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
